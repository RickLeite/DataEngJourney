{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/21 01:24:09 WARN Utils: Your hostname, wedivv-H110M-S2V resolves to a loopback address: 127.0.1.1; using 192.168.1.44 instead (on interface wlp5s0)\n",
      "23/05/21 01:24:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/05/21 01:24:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"MySql integration\")\n",
    "    .config(\"spark.jars\", \"/home/wedivv/Downloads/mysql-connector-j-8.0.33.jar\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\",\n",
    "    \"user\": \"username\",\n",
    "    \"password\": \"Pass1234*\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "|customer_id|store_id|first_name|last_name|               email|address_id|active|        create_date|        last_update|\n",
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "|          1|       1|      MARY|    SMITH|MARY.SMITH@sakila...|         5|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          2|       1|  PATRICIA|  JOHNSON|PATRICIA.JOHNSON@...|         6|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          3|       1|     LINDA| WILLIAMS|LINDA.WILLIAMS@sa...|         7|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          4|       2|   BARBARA|    JONES|BARBARA.JONES@sak...|         8|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          5|       1| ELIZABETH|    BROWN|ELIZABETH.BROWN@s...|         9|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          6|       2|  JENNIFER|    DAVIS|JENNIFER.DAVIS@sa...|        10|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          7|       1|     MARIA|   MILLER|MARIA.MILLER@saki...|        11|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          8|       2|     SUSAN|   WILSON|SUSAN.WILSON@saki...|        12|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          9|       2|  MARGARET|    MOORE|MARGARET.MOORE@sa...|        13|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         10|       1|   DOROTHY|   TAYLOR|DOROTHY.TAYLOR@sa...|        14|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         11|       2|      LISA| ANDERSON|LISA.ANDERSON@sak...|        15|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         12|       1|     NANCY|   THOMAS|NANCY.THOMAS@saki...|        16|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         13|       2|     KAREN|  JACKSON|KAREN.JACKSON@sak...|        17|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         14|       2|     BETTY|    WHITE|BETTY.WHITE@sakil...|        18|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         15|       1|     HELEN|   HARRIS|HELEN.HARRIS@saki...|        19|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         16|       2|    SANDRA|   MARTIN|SANDRA.MARTIN@sak...|        20| false|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         17|       1|     DONNA| THOMPSON|DONNA.THOMPSON@sa...|        21|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         18|       2|     CAROL|   GARCIA|CAROL.GARCIA@saki...|        22|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         19|       1|      RUTH| MARTINEZ|RUTH.MARTINEZ@sak...|        23|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|         20|       2|    SHARON| ROBINSON|SHARON.ROBINSON@s...|        24|  true|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF = ( \n",
    "    spark\n",
    "        .read\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/sakila\")\n",
    "        .option(\"dbtable\", \"customer\")\n",
    "        .options(**properties)\n",
    "        .load() \n",
    "        )\n",
    "\n",
    "# The double asterisks (**) are used to unpack the properties dictionary \n",
    "# and pass its contents as individual key-value arguments\n",
    "\n",
    "jdbcDF.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### inserting our own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data = [\n",
    "    (None, 1, \"Joaozinskyvoiqueinsverson\", \"da Silva\", \n",
    "     \"joaozika_verson@ig.com.br\", 1, 1, \n",
    "     datetime.now(), datetime.now())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), nullable=True),\n",
    "    StructField(\"store_id\", IntegerType(), nullable=False),\n",
    "    StructField(\"first_name\", StringType(), nullable=False),\n",
    "    StructField(\"last_name\", StringType(), nullable=False),\n",
    "    StructField(\"email\", StringType(), nullable=True),\n",
    "    StructField(\"address_id\", IntegerType(), nullable=False),\n",
    "    StructField(\"active\", IntegerType(), nullable=False),\n",
    "    StructField(\"create_date\", TimestampType(), nullable=False),\n",
    "    StructField(\"last_update\", TimestampType(), nullable=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/sakila\") \\\n",
    "    .option(\"dbtable\", \"customer\") \\\n",
    "    .options(**properties) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Achando o Joaozinskyvoiquinsverson da Silva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------------------------+---------+-------------------------+----------+------+-------------------+-------------------+\n",
      "|customer_id|store_id|first_name               |last_name|email                    |address_id|active|create_date        |last_update        |\n",
      "+-----------+--------+-------------------------+---------+-------------------------+----------+------+-------------------+-------------------+\n",
      "|602        |1       |Joaozinskyvoiqueinsverson|da Silva |joaozika_verson@ig.com.br|1         |true  |2023-05-21 01:24:17|2023-05-21 01:24:16|\n",
      "+-----------+--------+-------------------------+---------+-------------------------+----------+------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF = ( \n",
    "    spark\n",
    "        .read\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/sakila\")\n",
    "        .option(\"dbtable\", \"customer\")\n",
    "        .options(**properties)\n",
    "        .load() \n",
    "        )\n",
    "\n",
    "\n",
    "jdbcDF.where(\"first_name = 'Joaozinskyvoiqueinsverson'\").show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       SCHEMA_NAME|\n",
      "+------------------+\n",
      "|             mysql|\n",
      "|information_schema|\n",
      "|performance_schema|\n",
      "|               sys|\n",
      "|           desafio|\n",
      "|            sakila|\n",
      "|       board_games|\n",
      "|          datapipe|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "databasesDF = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/information_schema\") \\\n",
    "    .option(\"query\", \"SELECT SCHEMA_NAME FROM SCHEMATA\") \\\n",
    "    .options(**properties) \\\n",
    "    .load()\n",
    "\n",
    "# Show the list of databases\n",
    "databasesDF.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
