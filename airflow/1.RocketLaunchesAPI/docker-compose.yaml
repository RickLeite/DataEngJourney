# Meu docker-compose simples para airflow - 
# !! logs do airflow n√£o compartilhado com o host

version: '3.8'
x-environment:
  &airflow_environment
  - AIRFLOW__CORE__EXECUTOR=LocalExecutor
  - AIRFLOW__CORE__LOAD_EXAMPLES=False
  - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
  - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow

  - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
  - AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=True

  - AIRFLOW__CORE__STORE_DAG_CODE=True
  - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True
  - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True

x-airflow-image: &airflow_image apache/airflow:2.6.1-python3.10

services:
  postgres:
    image: postgres:15.3-alpine3.18
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"

  init:
    image: *airflow_image
    depends_on:
      - postgres
    environment: *airflow_environment
    entrypoint: /bin/bash
    command: -c 'airflow db init && airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email admin@example.org'

  webserver:
    image: *airflow_image
    restart: always
    depends_on:
      init:
        condition: service_completed_successfully
    ports:
      - "8080:8080"
    environment: *airflow_environment
    command: webserver

  scheduler:
    image: *airflow_image
    restart: always
    depends_on:
      init:
        condition: service_completed_successfully
    volumes:
      - ./rocket_launches.py:/opt/airflow/dags/rocket_launches.py
    environment: *airflow_environment
    command: scheduler
