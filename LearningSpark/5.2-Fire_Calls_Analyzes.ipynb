{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/10 00:10:32 WARN Utils: Your hostname, wedivv-H110M-S2V resolves to a loopback address: 127.0.1.1; using 192.168.1.44 instead (on interface wlp5s0)\n",
      "23/05/10 00:10:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/10 00:10:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "        .appName(\"Analyzing Fire Calls for Service data\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fire_df = spark.read.parquet(\"./data/5-Fire_Calls/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call_number',\n",
       " 'unit_id',\n",
       " 'incident_number',\n",
       " 'call_type',\n",
       " 'call_date',\n",
       " 'watch_date',\n",
       " 'call_final_disposition',\n",
       " 'available_dttm',\n",
       " 'address',\n",
       " 'city',\n",
       " 'zipcode_of_incident',\n",
       " 'battalion',\n",
       " 'station_area',\n",
       " 'box',\n",
       " 'original_priority',\n",
       " 'priority',\n",
       " 'final_priority',\n",
       " 'als_unit',\n",
       " 'call_type_group',\n",
       " 'number_of_alarms',\n",
       " 'unit_type',\n",
       " 'unit_sequence_in_call_dispatch',\n",
       " 'fire_prevention_district',\n",
       " 'supervisor_district',\n",
       " 'neighborhoods_analysis_boundaries',\n",
       " 'case_location',\n",
       " 'rowid']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+------------+\n",
      "|incident_number|available_dttm         |call_type   |\n",
      "+---------------+-----------------------+------------+\n",
      "|20136635       |2020-11-30T11:01:50.000|Alarms      |\n",
      "|21049045       |2021-04-24T08:20:17.000|Water Rescue|\n",
      "|21049045       |2021-04-24T08:20:15.000|Water Rescue|\n",
      "|21049045       |2021-04-24T08:19:54.000|Water Rescue|\n",
      "|21049045       |2021-04-24T08:19:33.000|Water Rescue|\n",
      "+---------------+-----------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "fewFireDF = (fire_df\n",
    "    .select(\"incident_number\", \"available_dttm\", \"call_type\")\n",
    "    .where(col(\"call_type\") != \"Medical Incident\"))\n",
    "\n",
    "fewFireDF.show(5, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|call_type                         |\n",
      "+----------------------------------+\n",
      "|Elevator / Escalator Rescue       |\n",
      "|Alarms                            |\n",
      "|Odor (Strange / Unknown)          |\n",
      "|Citizen Assist / Service Call     |\n",
      "|HazMat                            |\n",
      "|Explosion                         |\n",
      "|Vehicle Fire                      |\n",
      "|Suspicious Package                |\n",
      "|Other                             |\n",
      "|Outside Fire                      |\n",
      "|Traffic Collision                 |\n",
      "|Assist Police                     |\n",
      "|Gas Leak (Natural and LP Gases)   |\n",
      "|Water Rescue                      |\n",
      "|Electrical Hazard                 |\n",
      "|Structure Fire                    |\n",
      "|Industrial Accidents              |\n",
      "|Mutual Aid / Assist Outside Agency|\n",
      "|Fuel Spill                        |\n",
      "|Smoke Investigation (Outside)     |\n",
      "+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "(\n",
    "    fewFireDF\n",
    "    .select(\"call_type\")\n",
    "    .where(col(\"call_type\").isNotNull())\n",
    "    .distinct()\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               24|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "(\n",
    "    fewFireDF\n",
    "    .select(\"call_type\")\n",
    "    .where(col(\"call_type\").isNotNull())\n",
    "    .agg(count_distinct('call_type').alias('DistinctCallTypes'))\n",
    "   \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------------+-----------------------+\n",
      "|call_date              |watch_date             |available_dttm         |\n",
      "+-----------------------+-----------------------+-----------------------+\n",
      "|2021-04-24T00:00:00.000|2021-04-24T00:00:00.000|2021-04-24T10:26:57.000|\n",
      "|2021-04-24T00:00:00.000|2021-04-24T00:00:00.000|2021-04-24T10:46:41.000|\n",
      "|2020-11-30T00:00:00.000|2020-11-30T00:00:00.000|2020-11-30T11:01:50.000|\n",
      "|2021-04-24T00:00:00.000|2021-04-24T00:00:00.000|2021-04-24T10:32:33.000|\n",
      "|2021-04-24T00:00:00.000|2021-04-24T00:00:00.000|2021-04-24T09:50:34.000|\n",
      "+-----------------------+-----------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_df\n",
    "    .select(\"call_date\", \"watch_date\", \"available_dttm\")\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_ts_df = (\n",
    "    fire_df\n",
    "    .withColumn(\"IncidentDate\", to_timestamp(col(\"call_date\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "    .drop(\"call_date\")\n",
    "    .withColumn(\"OnWatchDate\", to_timestamp(col(\"watch_date\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "    .drop(\"watch_date\")\n",
    "    .withColumn(\"AvailableDtTS\", to_timestamp(col(\"available_dttm\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))   \n",
    "    .drop(\"available_dttm\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|       IncidentDate|        OnWatchDate|      AvailableDtTS|\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2021-04-24 00:00:00|2021-04-24 00:00:00|2021-04-24 10:26:57|\n",
      "|2021-04-24 00:00:00|2021-04-24 00:00:00|2021-04-24 10:46:41|\n",
      "|2020-11-30 00:00:00|2020-11-30 00:00:00|2020-11-30 11:01:50|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\")\n",
    " ).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2020|\n",
      "|              2021|\n",
      "|              2022|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select(year('IncidentDate'))\n",
    "    .distinct()\n",
    "    .orderBy(year('IncidentDate'))\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Year|count|\n",
      "+----+-----+\n",
      "|2020|  236|\n",
      "|2022|10564|\n",
      "|2021|14200|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "(fire_ts_df\n",
    "    .select(year('IncidentDate').alias('Year'), 'call_number')\n",
    "    .groupBy('Year')\n",
    "    .count()\n",
    "    .orderBy('count', ascending=True)\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----+\n",
      "|call_type                      |count|\n",
      "+-------------------------------+-----+\n",
      "|Medical Incident               |16865|\n",
      "|Alarms                         |3355 |\n",
      "|Structure Fire                 |1601 |\n",
      "|Traffic Collision              |931  |\n",
      "|Other                          |539  |\n",
      "|Outside Fire                   |487  |\n",
      "|Citizen Assist / Service Call  |367  |\n",
      "|Gas Leak (Natural and LP Gases)|179  |\n",
      "|Water Rescue                   |163  |\n",
      "|Electrical Hazard              |162  |\n",
      "+-------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select(\"call_type\")\n",
    "    .where(col(\"call_type\").isNotNull())\n",
    "    .groupBy(\"call_type\")\n",
    "    .count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    " \n",
    " ).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------------------+---------------------+\n",
      "|sum(number_of_alarms)|max(number_of_alarms)|min(number_of_alarms)|\n",
      "+---------------------+---------------------+---------------------+\n",
      "|              25109.0|                    3|                    1|\n",
      "+---------------------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "(fire_ts_df\n",
    "    .select(F.sum(\"number_of_alarms\"),\n",
    "            F.max(\"number_of_alarms\"),\n",
    "            F.min(\"number_of_alarms\")\n",
    "            )\n",
    " ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Year|count|\n",
      "+----+-----+\n",
      "|2020|  236|\n",
      "|2022|10564|\n",
      "|2021|14200|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select(year('IncidentDate').alias('Year'), 'call_number')\n",
    "    .groupBy('Year')\n",
    "    .count()\n",
    "    .orderBy('count', ascending=True)\n",
    ").show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploratory data analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were all the different types of fire calls in 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|call_type                                   |\n",
      "+--------------------------------------------+\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|Suspicious Package                          |\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "|Water Rescue                                |\n",
      "|Electrical Hazard                           |\n",
      "|Structure Fire                              |\n",
      "|Medical Incident                            |\n",
      "|Mutual Aid / Assist Outside Agency          |\n",
      "|Smoke Investigation (Outside)               |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Watercraft in Distress                      |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select(\"call_type\")\n",
    "    .distinct()\n",
    "    .where(year(\"IncidentDate\") == 2021)\n",
    ").show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What months within the year 2021 saw the highest number of fire calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|     call_type|\n",
      "+--------------+\n",
      "|  Outside Fire|\n",
      "|Structure Fire|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# type of fire calls\n",
    "\n",
    "(fire_ts_df\n",
    "    .select(\"call_type\")\n",
    "    .distinct()\n",
    "    .filter(col(\"call_type\").like(\"%Fire%\"))\n",
    "    .where(year(\"IncidentDate\") == 2021)\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|month|month_name|count|\n",
      "+-----+----------+-----+\n",
      "|    7|      July|  575|\n",
      "|    4|     April|  367|\n",
      "|   10|   October|  197|\n",
      "|    5|       May|   34|\n",
      "|    1|   January|   21|\n",
      "|    6|      June|    7|\n",
      "|    2|  February|    2|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select(month(\"IncidentDate\").alias('month'), date_format(\"IncidentDate\", \"MMMM\").alias(\"month_name\"), 'call_type')\n",
    "    .where(year(\"IncidentDate\") == 2021)\n",
    "    .filter(col(\"call_type\").like(\"%Fire%\"))\n",
    "    .groupBy(\"month\", \"month_name\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which neighborhood in San Francisco generated the most fire calls in 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|neighborhood         |count|\n",
      "+---------------------+-----+\n",
      "|Bayview Hunters Point|161  |\n",
      "|Tenderloin           |109  |\n",
      "|Mission              |98   |\n",
      "|Bernal Heights       |70   |\n",
      "|Nob Hill             |54   |\n",
      "+---------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select(col('neighborhoods_analysis_boundaries').alias('neighborhood'))\n",
    "    .where((col('city') == 'San Francisco') & (year(\"IncidentDate\") == 2021))\n",
    "    .filter(col(\"call_type\").like(\"%Fire%\"))\n",
    "    .groupBy('neighborhood')\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "\n",
    ").show(5, truncate=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which week in the year 2021 had the most fire calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|week|count|\n",
      "+----+-----+\n",
      "|  16|  352|\n",
      "|  26|  313|\n",
      "|  27|  228|\n",
      "|  40|  135|\n",
      "|  41|   43|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select(weekofyear(col(\"IncidentDate\")).alias(\"week\"))\n",
    "    .where(year(\"IncidentDate\") == 2021)\n",
    "    .filter(col(\"call_type\").like(\"%Fire%\"))\n",
    "    .groupBy(\"week\")\n",
    "    .count()\n",
    "    .orderBy(desc('count'))\n",
    "\n",
    ").show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a correlation between neighborhood, zip code, and number of fire calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_calls = (fire_ts_df\n",
    "    .select(col(\"neighborhoods_analysis_boundaries\").alias(\"neighborhood\"))\n",
    "    .filter(col(\"call_type\").like(\"%Fire%\"))\n",
    "    .groupBy(\"neighborhood\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_calls = (fire_ts_df\n",
    "    .select(col(\"zipcode_of_incident\").alias(\"zipcode\"))\n",
    "    .filter(col(\"call_type\").like(\"%Fire%\"))\n",
    "    .groupBy(\"zipcode\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between neighborhood and number of fire calls: -0.4264014327112209\n",
      "Correlation between zip code and number of fire calls: -0.6610536903660496\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE OF CORRELATION, gepito \n",
    "\n",
    "from pyspark.sql.functions import col, corr\n",
    "\n",
    "# create a DataFrame from your data\n",
    "data = [\n",
    "    ('Excelsior', '94112', 10),\n",
    "    ('Sunset', '94122', 5),\n",
    "    ('Richmond', '94118', 3),\n",
    "    ('Marina', '94123', 7),\n",
    "    ('Mission', '94110', 15),\n",
    "    ('Bernal Heights', '94110', 8),\n",
    "    ('Castro/Upper Market', '94114', 6),\n",
    "    ('Outer Mission', '94112', 12),\n",
    "    ('Twin Peaks', '94131', 4),\n",
    "    ('Pacific Heights', '94115', 2)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, ['neighborhood', 'zipcode', 'num_calls'])\n",
    "\n",
    "# create a vector column for each categorical variable using StringIndexer\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "indexer = StringIndexer(inputCol='neighborhood', outputCol='neighborhood_index')\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "indexer = StringIndexer(inputCol='zipcode', outputCol='zipcode_index')\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# create a vector column for the features\n",
    "assembler = VectorAssembler(inputCols=['neighborhood_index', 'zipcode_index'], outputCol='features')\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# compute the correlations\n",
    "neighborhood_vec = col('neighborhood_index')\n",
    "zipcode_vec = col('zipcode_index')\n",
    "num_calls = col('num_calls')\n",
    "\n",
    "correlation = df.select(\n",
    "    corr(neighborhood_vec, num_calls), \n",
    "    corr(zipcode_vec, num_calls)\n",
    ").first()\n",
    "\n",
    "print(f\"Correlation between neighborhood and number of fire calls: {correlation[0]}\")\n",
    "print(f\"Correlation between zip code and number of fire calls: {correlation[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
